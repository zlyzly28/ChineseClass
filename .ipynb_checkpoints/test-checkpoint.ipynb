{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1da34ff-9526-4cf9-80f3-8ea803afef58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T02:47:28.182249Z",
     "iopub.status.busy": "2024-07-15T02:47:28.181911Z",
     "iopub.status.idle": "2024-07-15T02:47:28.928830Z",
     "shell.execute_reply": "2024-07-15T02:47:28.928282Z",
     "shell.execute_reply.started": "2024-07-15T02:47:28.182229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from train_eval import train, init_network\n",
    "from importlib import import_module\n",
    "import argparse\n",
    "dataset = 'THUCNews'  # 数据集\n",
    "\n",
    "# 搜狗新闻:embedding_SougouNews.npz, 腾讯:embedding_Tencent.npz, 随机初始化:random\n",
    "embedding = 'embedding_SougouNews.npz'\n",
    "\n",
    "model_name = 'TextRCNN'  # 'TextRCNN'  # TextCNN, TextRNN, FastText, TextRCNN, TextRNN_Att, DPCNN, Transformer\n",
    "\n",
    "from utils import build_dataset, build_iterator, get_time_dif\n",
    "\n",
    "x = import_module('models.' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1415aa-2351-40ef-a102-87c300fc5fa7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-15T02:47:30.912698Z",
     "iopub.status.busy": "2024-07-15T02:47:30.912295Z",
     "iopub.status.idle": "2024-07-15T02:47:30.979886Z",
     "shell.execute_reply": "2024-07-15T02:47:30.979262Z",
     "shell.execute_reply.started": "2024-07-15T02:47:30.912677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = x.Config(dataset, embedding)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "torch.backends.cudnn.deterministic = True  # 保证每次结果一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6edb20-74ca-42a6-ad9f-fb9e08d5a291",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-15T02:47:48.000179Z",
     "iopub.status.busy": "2024-07-15T02:47:47.999788Z",
     "iopub.status.idle": "2024-07-15T02:47:49.844909Z",
     "shell.execute_reply": "2024-07-15T02:47:49.844323Z",
     "shell.execute_reply.started": "2024-07-15T02:47:48.000158Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180000it [00:01, 114935.30it/s]\n",
      "10000it [00:00, 131912.53it/s]\n",
      "10000it [00:00, 51791.44it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "vocab, train_data, dev_data, test_data = build_dataset(config, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f35130-50c4-46a4-9271-77e256e8f5d6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-15T02:48:21.020883Z",
     "iopub.status.busy": "2024-07-15T02:48:21.020454Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = np.random.rand(len(vocab), 300)\n",
    "pretrain_dir = \"THUCNews/data/sgns.sogou.char\"\n",
    "f = open(pretrain_dir, \"r\", encoding='UTF-8')\n",
    "for i, line in enumerate(f.readlines()):\n",
    "    \n",
    "    # if i == 0:  # 若第一行是标题，则跳过\n",
    "    #     continue\n",
    "    lin = line.strip().split(\" \")\n",
    "    print(lin)\n",
    "    if lin[0] in vocab:\n",
    "        idx = vocab[lin[0]]\n",
    "        emb = [float(x) for x in lin[1:301]]\n",
    "        embeddings[idx] = np.asarray(emb, dtype='float32')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded28839-9cb3-4a29-a4bb-f03bebfc1024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0063007-d015-4a83-b9c2-3505958cfc36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T02:46:23.136316Z",
     "iopub.status.busy": "2024-07-15T02:46:23.135997Z",
     "iopub.status.idle": "2024-07-15T02:47:09.424435Z",
     "shell.execute_reply": "2024-07-15T02:47:09.423916Z",
     "shell.execute_reply.started": "2024-07-15T02:46:23.136297Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'THUCNews/data/sgns.sogou.char.bz2' has been successfully decompressed to 'THUCNews/data/sgns.sogou.char'.\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import os\n",
    "\n",
    "def decompress_bz2(file_path):\n",
    "    # 获取文件的基本路径和名称，用于构造解压后的文件名\n",
    "    base_path, filename = os.path.split(file_path)\n",
    "    output_file = os.path.join(base_path, filename[:-4])  # 移除'.bz2'扩展名\n",
    "    \n",
    "    with bz2.open(file_path, 'rb') as f_in:\n",
    "        with open(output_file, 'wb') as f_out:\n",
    "            data = f_in.read()\n",
    "            f_out.write(data)\n",
    "    \n",
    "    print(f\"File '{file_path}' has been successfully decompressed to '{output_file}'.\")\n",
    "\n",
    "# 指定你的.bz2文件路径\n",
    "bz2_file_path = 'THUCNews/data/sgns.sogou.char.bz2'\n",
    "\n",
    "# 调用函数解压文件\n",
    "decompress_bz2(bz2_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da137bde-11ea-4437-b0d3-0327779822d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b4ab42-3c8b-4ecb-aa04-ed2be05085ce",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-15T03:00:13.290475Z",
     "iopub.status.busy": "2024-07-15T03:00:13.290085Z",
     "iopub.status.idle": "2024-07-15T03:00:21.885247Z",
     "shell.execute_reply": "2024-07-15T03:00:21.884662Z",
     "shell.execute_reply.started": "2024-07-15T03:00:13.290455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import build_dataset, build_iterator, get_time_dif, build_vocab\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "MAX_VOCAB_SIZE = 10000  # 词表长度限制\n",
    "UNK, PAD = '<UNK>', '<PAD>'  # 未知字，padding符号\n",
    "'''提取预训练词向量'''\n",
    "# 下面的目录、文件名按需更改。\n",
    "train_dir = \"Newtrain/data/train.txt\"\n",
    "vocab_dir = \"Newtrain/data/vocab.pkl\"\n",
    "pretrain_dir = \"THUCNews/data/sgns.sogou.char\"\n",
    "emb_dim = 300\n",
    "filename_trimmed_dir = \"Newtrain/data/embedding_Newtrain\"\n",
    "if os.path.exists(vocab_dir):\n",
    "    word_to_id = pkl.load(open(vocab_dir, 'rb'))\n",
    "else:\n",
    "    # tokenizer = lambda x: x.split(' ')  # 以词为单位构建词表(数据集中词之间以空格隔开)\n",
    "    tokenizer = lambda x: [y for y in x]  # 以字为单位构建词表\n",
    "    word_to_id = build_vocab(train_dir, tokenizer=tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=1)\n",
    "    pkl.dump(word_to_id, open(vocab_dir, 'wb'))\n",
    "\n",
    "embeddings = np.random.rand(len(word_to_id), emb_dim)\n",
    "f = open(pretrain_dir, \"r\", encoding='UTF-8')\n",
    "for i, line in enumerate(f.readlines()):\n",
    "    # if i == 0:  # 若第一行是标题，则跳过\n",
    "    #     continue\n",
    "    lin = line.strip().split(\" \")\n",
    "    if lin[0] in word_to_id:\n",
    "        idx = word_to_id[lin[0]]\n",
    "        emb = [float(x) for x in lin[1:301]]\n",
    "        embeddings[idx] = np.asarray(emb, dtype='float32')\n",
    "f.close()\n",
    "np.savez_compressed(filename_trimmed_dir, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c99ed5e1-c9d1-48bf-8206-c5ca8b2f10cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:12:26.951585Z",
     "iopub.status.busy": "2024-07-15T04:12:26.951142Z",
     "iopub.status.idle": "2024-07-15T04:12:26.956868Z",
     "shell.execute_reply": "2024-07-15T04:12:26.956305Z",
     "shell.execute_reply.started": "2024-07-15T04:12:26.951553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{word_count[0]: idx for idx, word_count in enumerate([('a', 3), ('b', 2), ('c', 1)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cce37e8-4f1f-49c8-a897-1528e87e0f2a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-15T03:29:46.462183Z",
     "iopub.status.busy": "2024-07-15T03:29:46.461835Z",
     "iopub.status.idle": "2024-07-15T03:29:46.465227Z",
     "shell.execute_reply": "2024-07-15T03:29:46.464746Z",
     "shell.execute_reply.started": "2024-07-15T03:29:46.462164Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.46,  Test Acc: 89.00%\n"
     ]
    }
   ],
   "source": [
    "msg = 'Test Loss: {0:>5.2},  Test Acc: {1:>5.2%}'\n",
    "print(msg.format(0.458, 0.89))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
